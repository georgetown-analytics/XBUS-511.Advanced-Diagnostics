{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Grappling with Covariance\n",
    "XBUS-511: Diagnostics for More Informed Machine Learning\n",
    "\n",
    "In this exercise, we will explore a few datasets that exhibit covariance, and see what we can do to prepare the data for machine learning.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, fname):\n",
    "    \"\"\"\n",
    "    Helper method to retrieve data.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    outpath  = os.path.abspath(fname)\n",
    "    with open(outpath, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return outpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressing Facebook Post Comments \n",
    "\n",
    "\n",
    "Thanks to [this team](https://github.com/Wall-eSociety/CommentVolumeML) for figuring out the labels for this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directory where we'll store data\n",
    "FIXTURES = os.path.join(\"..\", \"fixtures\")\n",
    "if not os.path.exists(FIXTURES):\n",
    "    os.makedirs(FIXTURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and unzip the data\n",
    "\n",
    "URL = \"https://tinyurl.com/y2ks5fjf\"\n",
    "ZIPPED_FILES = \"facebook_data.zip\"\n",
    "UNZIPPED_FILES = \"facebook_data\"\n",
    "\n",
    "zipped_data = fetch_data(\n",
    "    URL, \n",
    "    os.path.join(FIXTURES, ZIPPED_FILES)\n",
    ")\n",
    "\n",
    "with zipfile.ZipFile(\n",
    "    os.path.join(FIXTURES, ZIPPED_FILES), \"r\"\n",
    ") as zfiles:\n",
    "    zfiles.extractall(\n",
    "        os.path.join(FIXTURES, UNZIPPED_FILES)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        FIXTURES, \n",
    "        UNZIPPED_FILES, \n",
    "        \"Dataset\", \n",
    "        \"Training\", \n",
    "        \"Features_Variant_2.csv\"\n",
    "    ),\n",
    "    header=None\n",
    ")\n",
    "columns = [\n",
    "    \"likes\", \"views\", \"returns\", \"category\", \"derived_1\", \n",
    "    \"derived_2\", \"derived_3\", \"derived_4\", \"derived_5\",\n",
    "    \"derived_6\", \"derived_7\", \"derived_8\", \"derived_9\",\n",
    "    \"derived_10\", \"derived_11\", \"derived_12\", \"derived_13\",\n",
    "    \"derived_14\", \"derived_15\", \"derived_16\", \"derived_17\",\n",
    "    \"derived_18\", \"derived_19\", \"derived_20\", \"derived_21\",\n",
    "    \"derived_22\", \"derived_23\", \"derived_24\", \"derived_25\",\n",
    "    \"cc_1\", \"cc_2\", \"cc_3\", \"cc_4\", \"cc_5\", \"base_time\",\n",
    "    \"length\", \"shares\", \"status\", \"h_local\", \"sunday_post\",\n",
    "    \"monday_post\", \"tuesday_post\", \"wednesday_post\",\n",
    "    \"thursday_post\", \"friday_post\", \"saturday_post\",\n",
    "    \"sunday_base\", \"monday_base\", \"tuesday_base\",\n",
    "    \"wednesday_base\", \"thursday_base\", \"friday_base\",\n",
    "    \"saturday_base\", \"target\"\n",
    "]\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into features and target\n",
    "target = \"target\"\n",
    "\n",
    "X = df.loc[:, df.columns != target].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Covariance in the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Regression Model\n",
    "\n",
    "The goal is to build a model that can predict the number of comments a Facebook post would receive, given the features available about the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizing Credit Card Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data\n",
    "URL = \"https://datahub.io/machine-learning/creditcard/r/creditcard.csv\"\n",
    "FNAME = \"creditcard.csv\"\n",
    "data = fetch_data(URL, os.path.join(FIXTURES, FNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a dataframe\n",
    "df = pd.read_csv(os.path.join(FIXTURES, FNAME))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into features and target\n",
    "target = \"Class\"\n",
    "\n",
    "X = df.loc[:, df.columns != target].values\n",
    "y = df[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Covariance in the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Classifier\n",
    "\n",
    "Your goal is to build a classification model that can predict fraud given input features that describe credit card transaction behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
